{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2062acfa-84b6-478b-9b3c-e4261fca6342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mc du is  0\n",
      "number of layers 2\n",
      "layer index 0\n",
      "layer index 1\n",
      "ethreshold = \n",
      "8\n",
      "(50, 10)\n",
      "(50, 200)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# !SLURM=1 LOIHI_GEN=N3B3 PARTITION=oheogulch_2h\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from lava.magma.core.learning.learning_rule import Loihi2FLearningRule\n",
    "from lava.magma.core.learning.learning_rule import LoihiLearningRule\n",
    "from lava.proc.lif.process import LIF, LearningLIF\n",
    "from lava.proc.dense.process import LearningDense, Dense, DelayDense\n",
    "from lava.proc.lif.process import LIFReset\n",
    "from lava.utils.weightutils import SignMode\n",
    "\n",
    "from lava.proc.dense.process import Dense\n",
    "\n",
    "from lava.magma.core.run_configs import Loihi2HwCfg ,Loihi2SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.magma.core.callback_fx import NxSdkCallbackFx\n",
    "from lava.proc.learning_rules.stdp_learning_rule import STDPLoihi\n",
    "from lava.proc.monitor.process import Monitor\n",
    "from lava.magma.core.learning.learning_rule import Loihi2FLearningRule\n",
    "from lava.proc.monitor.process import Monitor\n",
    "import time\n",
    "\n",
    "\n",
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import InPort, OutPort\n",
    "\n",
    "\n",
    "class Lif(AbstractProcess):\n",
    "    \"\"\"Leaky-Integrate-and-Fire neural process with activation input and spike\n",
    "    output ports a_in and s_out.\n",
    "\n",
    "    Realizes the following abstract behavior:\n",
    "    u[t] = u[t-1] * (1-du) + a_in\n",
    "    v[t] = v[t-1] * (1-dv) + u[t] + bias\n",
    "    s_out = v[t] > vth\n",
    "    v[t] = v[t] - s_out*vth\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "       super().__init__(**kwargs)\n",
    "       shape = kwargs.get(\"shape\", (1,))\n",
    "       self.a_in = InPort(shape=shape)\n",
    "       self.s_out = OutPort(shape=shape)\n",
    "       self.u = Var(shape=shape, init=0)\n",
    "       self.v = Var(shape=shape, init=0)\n",
    "       self.du = Var(shape=(1,), init=kwargs.pop(\"du\", 0))\n",
    "       self.dv = Var(shape=(1,), init=kwargs.pop(\"dv\", 0))\n",
    "       self.bias_mant = Var(shape=shape, init=kwargs.pop(\"bias_mant\", 0))\n",
    "       self.bias_exp = Var(shape=shape, init=kwargs.pop(\"bias_exp\", 0))\n",
    "       self.vmin_exp = Var(shape=shape, init=kwargs.pop(\"vmin_exp\", 23))\n",
    "       self.vmax_exp = Var(shape=shape, init=kwargs.pop(\"vmax_exp\", 23))\n",
    "       self.vth = Var(shape=(1,), init=kwargs.pop(\"vth\", 64))\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.model.py.ports import PyInPort, PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "from lava.magma.core.resources import CPU\n",
    "from lava.magma.core.decorator import implements, requires\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "from lava.proc.lif.process import LIF\n",
    "\n",
    "\n",
    "@implements(proc=Lif, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PyLifModel(PyLoihiProcessModel):\n",
    "    a_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, np.int16, precision=16)\n",
    "    s_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "    u: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=24)\n",
    "    v: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=24)\n",
    "    bias_mant: np.ndarray = LavaPyType(np.ndarray, np.int16, precision=12)\n",
    "    bias_exp: np.ndarray = LavaPyType(np.ndarray, np.int16, precision=12)\n",
    "    du: int = LavaPyType(int, np.uint16, precision=12)\n",
    "    dv: int = LavaPyType(int, np.uint16, precision=12)\n",
    "    vmin_exp: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=24)\n",
    "    vmax_exp: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=24)\n",
    "    vth: int = LavaPyType(int, int, precision=8)\n",
    "\n",
    "    def run_spk(self):\n",
    "        bias = self.bias_mant*2**self.bias_exp\n",
    "        self.u[:] = self.u * ((2 ** 12 - self.du) // 2 ** 12)\n",
    "        a_in_data = 2**6*self.a_in.recv()\n",
    "        self.u[:] += a_in_data\n",
    "        self.v[:] = self.v * ((2 ** 12 - self.dv) // 2 ** 12) + (self.u) + bias\n",
    "        #rescale voltage\n",
    "        s_out = self.v >self.vth\n",
    "\n",
    "        min = -2**self.vmin_exp+1\n",
    "        #determine the minimum voltage\n",
    "        self.v[self.v < -1] = -1\n",
    "\n",
    "        \n",
    "        self.v[s_out] = 0  # Reset voltage to 0. This is Loihi-1 compatible.\n",
    "        self.s_out.send(s_out)\n",
    "\n",
    "\n",
    "\n",
    "SELECT_TAG = \"fixed_pt\"\n",
    "\n",
    "#convert fixed point paras to floating point settings\n",
    "def converter(du,dv,vth):\n",
    "    vth = vth*2**6\n",
    "    return du,dv,vth\n",
    "    \n",
    "\n",
    "\n",
    "def init_wgts(wmin, wmax, wdes, wsrc, sd):\n",
    "    # np.random.seed((sd+1)*10)\n",
    "\n",
    "    tmpp = np.random.normal(0, np.sqrt(3.0 / float(wsrc)), [wdes, wsrc])\n",
    "\n",
    "    # wgts = tmpp * wmax\n",
    "\n",
    "    # wm = np.max(tmpp)\n",
    "    # wgts = tmpp * float(wmax/wm)\n",
    "    # wgts = np.clip(wgts, -255, 255)\n",
    "\n",
    "    amx = np.max(tmpp)\n",
    "    amn = np.min(tmpp)\n",
    "    a1 = (tmpp - amn) / (amx - amn)\n",
    "    a1 = a1 * (wmax - wmin) + wmin\n",
    "    wgts = np.clip(a1, a_min=wmin, a_max=wmax)\n",
    "\n",
    "    # wgts = np.random.randint(low=wmin, high=wmax, size=(wdes, wsrc))\n",
    "\n",
    "    wgts = wgts.astype(int)\n",
    "\n",
    "    return wgts\n",
    "\n",
    "\n",
    "def init_th(wsrc, layer, scale, wmax):\n",
    "    hThr = float(scale/(1)) * wmax * wsrc * (np.sqrt(3.0 / float(wsrc)) / (2.0))\n",
    "    # hThr = float(scale) * wmax * wsrc * (np.sqrt(3.0 / float(wsrc)) / (2.0))\n",
    "    #     hThr = float(scale / (layer + 1)) * wmax * wsrc * 1.0 * 0.5\n",
    "    hThr = int(hThr)\n",
    "    return hThr\n",
    "\n",
    "\n",
    "class emstdp:\n",
    "    def __init__(self,\n",
    "                 numInputs = 200,\n",
    "                 numHidNurns = [100,10],\n",
    "                 num_steps = 128\n",
    "                 ):\n",
    "        # make sure the type of the parameters class\n",
    "        # copy the parameters\n",
    "\n",
    "\n",
    "\n",
    "        self.stim2bias = [int(1) for i in range(1)]\n",
    "        self.stim2bias += [int(i * 1) for i in range(1, 256, 1)]\n",
    "        self.train_data = []\n",
    "        self.train_label = []\n",
    "        self.numHidNurns =  numHidNurns\n",
    "        self.numlayers = len(self.numHidNurns)\n",
    "        self.numInputs = numInputs\n",
    "        self.numMCs = self.numInputs\n",
    "        self.numTargets = 10\n",
    "        '''\n",
    "        GC is the intermediate layer neurons\n",
    "        '''\n",
    "        self.numHidNurns = numHidNurns\n",
    "        self.numGCs = np.sum(self.numHidNurns)\n",
    "\n",
    "\n",
    "        # self.poswgtrng = 48\n",
    "        # self.negwgtrng = -96\n",
    "\n",
    "        # self.bposwgtrng = 48\n",
    "        # self.bnegwgtrng = -96\n",
    "\n",
    "        self.poswgtrng = 128\n",
    "        self.negwgtrng = -128\n",
    "\n",
    "        self.bposwgtrng = 255\n",
    "        self.bnegwgtrng = -255\n",
    "        \n",
    "        # self.poswgtrng = 64\n",
    "        # self.negwgtrng = -64\n",
    "\n",
    "        # self.bposwgtrng = 128\n",
    "        # self.bnegwgtrng = -128\n",
    "        \n",
    "        self.inputs = []\n",
    "        \n",
    "        self.ec_pos =[[None],[None]]\n",
    "        self.ec_neg = [[None],[None]]\n",
    "        self.ec_tmp_pos =[[None],[None]]\n",
    "        self.ec_tmp_neg = [[None],[None]]\n",
    "        \n",
    "        self.ec_pos_aux = [[None],[None]]\n",
    "        self.ec_neg_aux = [[None],[None]]\n",
    "\n",
    "        # probes related data structures\n",
    "        self.allMCSomaProbes = None\n",
    "        self.exc2InhConnProbes = None\n",
    "        self.inh2ExcConnProbesPos = None\n",
    "        self.inh2ExcConnProbesNeg = None\n",
    "        self.mcADProbes = None\n",
    "        self.mcSomaProbes = None\n",
    "        self.gcProbes = None\n",
    "        self.label = None\n",
    "        self.numStepsRan = 0\n",
    "        self.wgt_exp = dict()\n",
    "\n",
    "        #weights for testing use\n",
    "        self.hid_wgt = []\n",
    "        self.out_wgt = []\n",
    "\n",
    "        #testing usage\n",
    "        self.test_inter = []\n",
    "        self.test_out = []\n",
    "        self.test_connections = []\n",
    "        #probes\n",
    "        self.out_probe = []\n",
    "\n",
    "        \n",
    "    def setupNetwork(self, train, wgt, bwgt):\n",
    "        \"\"\" setups the EPL network \"\"\"\n",
    "\n",
    "        if train:\n",
    "            self.trainbool = 1\n",
    "        else:\n",
    "            self.trainbool = 0\n",
    "\n",
    "        self.allMCSomaGrp = None\n",
    "        self.allLabelGrp = None\n",
    "        self.wtaGrp = None\n",
    "\n",
    "        self.allGCsPerPattern = dict()\n",
    "        self.allPosECsPerPattern = dict()\n",
    "        self.pos_ec_soma = None\n",
    "        self.pos_ec_denrite = None\n",
    "        self.allNegECsPerPattern = dict()\n",
    "        self.neg_ec_soma = None\n",
    "        self.neg_ec_dendrite = None\n",
    "        self.allTmpPosECsPerPattern = dict()\n",
    "        self.allTmpNegECsPerPattern = dict()\n",
    "\n",
    "        self.forwardConns = dict()\n",
    "        self.posbackwardConns = dict()\n",
    "        self.negbackwardConns = dict()\n",
    "        self.hiddens = dict()\n",
    "\n",
    "        '''\n",
    "        Create input patterns\n",
    "        '''\n",
    "        self.createMCNeurons()\n",
    "\n",
    "        '''\n",
    "        create label layer\n",
    "        '''\n",
    "        # du,dv,vth = converter(4095,0,2)\n",
    "        self.allLabelGrp = self.create_cx(patternIdx= -1,du=int(4095),dv=0,vth=2)\n",
    "\n",
    "        print(\"number of layers\", self.numlayers)\n",
    "\n",
    "        for patternIdx in range(self.numlayers):\n",
    "            '''\n",
    "            Hidden layers\n",
    "            ''' \n",
    "            \n",
    "            self.inhid_vth = 0.5 #0.3 # first layer threshold\n",
    "            self.hid_vth = 0.3 # middle layer threshold\n",
    "            self.classifier_vth = 0.3 # 0.5 # classifier layer threshold\n",
    "            self.biasEx = 0 # bias exponential\n",
    "            self.biasMn = 0 # bias mantissa default\n",
    "\n",
    "            scale = 1\n",
    "            self.GCtoECDelayDeriv = int(10)\n",
    "            # self.ECtoGCDelayDeriv = int(2)\n",
    "            self.wtadelay = int(0)\n",
    "            # self.lastECdelay = int(0)\n",
    "            self.voldcy = int(0)\n",
    "            self.curdcy = int(4000)\n",
    "\n",
    "\n",
    "            self.ECtoGCwgt = 255\n",
    "            self.LabeltoECwgt = 8\n",
    "\n",
    "            thold = 0\n",
    "            wsrc = 0\n",
    "            \n",
    "            # calculating forward and error path thresholds\n",
    "            if patternIdx == self.numlayers - 1:\n",
    "                wsrc = self.numHidNurns[patternIdx - 1]\n",
    "                thold = init_th(wsrc, patternIdx, self.classifier_vth, 255)\n",
    "                self.biasMn = int(thold / 10)\n",
    "                ref = 1\n",
    "                ethold = int(self.LabeltoECwgt)\n",
    "            elif patternIdx == 0:\n",
    "                wsrc = self.numMCs\n",
    "                thold = init_th(wsrc, patternIdx, self.inhid_vth, 255)\n",
    "                self.biasMn = int(thold / 10)\n",
    "                ref = 1\n",
    "                if self.numlayers == 2:\n",
    "                    ethold = int(self.LabeltoECwgt)\n",
    "                else:\n",
    "                    ethold = int(init_th(self.numHidNurns[patternIdx + 1], patternIdx, self.inhid_vth, 255) / (patternIdx + 2))\n",
    "                    # ethold = int(self.LabeltoECwgt) + (self.numlayers - patternIdx - 2)*ethold\n",
    "            else:\n",
    "                wsrc = self.numHidNurns[patternIdx - 1]\n",
    "                thold = init_th(wsrc, patternIdx, self.hid_vth, 255)\n",
    "                self.biasMn = int(thold / 10)\n",
    "                ref = 1\n",
    "                ethold = int(init_th(self.numHidNurns[patternIdx + 1], patternIdx, self.hid_vth, 255) / (patternIdx + 2))\n",
    "            numTmps = int(np.ceil(thold / 255))\n",
    "            # weight exponential from intermediate error neurons to forward path\n",
    "            ijexp = int(np.ceil(np.log2(numTmps)) + 1)\n",
    "            # weight exponenital\n",
    "            self.wgt_exp[patternIdx] = ijexp\n",
    "\n",
    "            if patternIdx != self.numlayers - 1:\n",
    "                # self.allPosECsPerPattern[patternIdx] = self.net.createNeuronGroup()\n",
    "                # self.allNegECsPerPattern[patternIdx] = self.net.createNeuronGroup()\n",
    "                # self.allTmpPosECsPerPattern[patternIdx] = self.net.createCompartmentGroup()\n",
    "                # self.allTmpNegECsPerPattern[patternIdx] = self.net.createCompartmentGroup()\n",
    "                '''\n",
    "                initialize posEC, negEC, tmp PosEC, tmp negEC\n",
    "                posEC_soma: soma_du = 4095,soma_dv=0, bias_mant =0, vth =ethod\n",
    "                pos_ec_denrite: du= 0, dv= 0, vth =2,\n",
    "                \n",
    "                negEC soma: du= 4095 ,dv=0 , vth = ehold,\n",
    "                negEC dendrite: \n",
    "                '''\n",
    "                # pos ec\n",
    "                # self.allPosECsPerPattern[patternIdx] = andSoma(shape = self.numHidNurns[patternIdx])\n",
    "                self.allPosECsPerPattern[patternIdx] = self.create_cx(patternIdx =patternIdx,du = 4095,dv = 4095,vth = 3)\n",
    "                self.pos_ec_soma = self.create_cx(patternIdx =patternIdx, du=4095,dv=0, vth = ethold,\n",
    "                                                  vmin_exp= 10)\n",
    "                self.pos_ec_dendrite = self.create_cx(patternIdx = patternIdx, du=0,dv=0,vth =2,\n",
    "                                                      vmin_exp=10)\n",
    "                # neg ec\n",
    "                # self.allNegECsPerPattern[patternIdx] = andSoma(shape = self.numHidNurns[patternIdx])\n",
    "                self.allNegECsPerPattern[patternIdx] = self.create_cx(patternIdx =patternIdx,du = 4095,dv = 4095,vth = 3)\n",
    "                self.neg_ec_soma= self.create_cx(patternIdx = patternIdx, du=4095,dv=0, vth = ethold,\n",
    "                                                 vmin_exp= 10)\n",
    "                self.neg_ec_dendrite = self.create_cx(patternIdx= patternIdx, du=0,dv=0,vth =2,\n",
    "                                                      vmin_exp= 10)\n",
    "                \n",
    "\n",
    "            else:\n",
    "                '''\n",
    "                du =0 , dv =0, vth =2,\n",
    "                '''\n",
    "                self.allPosECsPerPattern[patternIdx] = self.create_cx(patternIdx= patternIdx, \n",
    "                                                                      du =4095, dv =0 ,\n",
    "                                                                      vth =ethold,\n",
    "                                                                      vmin_exp= 10)\n",
    "            \n",
    "                self.allNegECsPerPattern[patternIdx] = self.create_cx(patternIdx= patternIdx, \n",
    "                                                                      du =4095, dv =0 ,vth =ethold,\n",
    "                                                                      vmin_exp= 10)\n",
    "                \n",
    "            '''\n",
    "            ec tmp pos: du =4095, dv =0, vthMant = 2\n",
    "            ec tmp neg: du= 4095, dv =0, vthMant = 2\n",
    "            '''\n",
    "            self.allTmpPosECsPerPattern[patternIdx] = self.create_cx(patternIdx= patternIdx,\n",
    "                                                                      du =4095,dv=0 ,vth =2,\n",
    "                                                                      vmin_exp= 10)\n",
    "            self.allTmpNegECsPerPattern[patternIdx] = self.create_cx(patternIdx= patternIdx, \n",
    "                                                                     du =4095, dv=0,vth =2,\n",
    "                                                                     vmin_exp= 10)\n",
    "            #create GC neurons per pattern\n",
    "            print(\"layer index\", patternIdx)\n",
    "            self.createGCNeuronsPerPattern(patternIdx)\n",
    "            \n",
    "        self.connectforwardConns(train, wgt)\n",
    "        self.connectbackwardConns(bwgt)\n",
    "\n",
    "    def create_cx(self,patternIdx, du,dv,vth,bias_mant =0, \n",
    "                   bias_exp =0,vmin_exp = 23,vmax_exp = 23):\n",
    "        du,dv,vth = converter(du,dv,vth)\n",
    "        return Lif(shape = (self.numHidNurns[patternIdx],),\n",
    "                   du = du,\n",
    "                   dv = dv,\n",
    "                   vth = vth,\n",
    "                   bias_mant = bias_mant,\n",
    "                   bias_exp = bias_exp,\n",
    "                   vmin_exp = vmin_exp,\n",
    "                   )\n",
    "    def createTestGC(self, patternIdx):\n",
    "                \n",
    "            self.inhid_vth = 0.5 #0.3 # first layer threshold\n",
    "            self.hid_vth = 0.3 # middle layer threshold\n",
    "            self.classifier_vth = 0.3 # 0.5 # classifier layer threshold\n",
    "            self.biasEx = 0 # bias exponential\n",
    "            self.biasMn = 0 # bias mantissa default\n",
    "\n",
    "            scale = 1\n",
    "            self.GCtoECDelayDeriv = int(10)\n",
    "            # self.ECtoGCDelayDeriv = int(2)\n",
    "            self.wtadelay = int(0)\n",
    "            # self.lastECdelay = int(0)\n",
    "            self.voldcy = int(0)\n",
    "            self.curdcy = int(4000)\n",
    "\n",
    "            self.wtadelay = int(0)\n",
    "\n",
    "            self.ECtoGCwgt = 255\n",
    "            self.LabeltoECwgt = 8\n",
    "\n",
    "            thold = 0\n",
    "            wsrc = 0\n",
    "            \n",
    "            # calculating forward and error path thresholds\n",
    "            if patternIdx == self.numlayers - 1:\n",
    "                wsrc = self.numHidNurns[patternIdx - 1]\n",
    "                thold = init_th(wsrc, patternIdx, self.classifier_vth, 255)\n",
    "                self.biasMn = int(thold / 10)\n",
    "                ref = 1\n",
    "                ethold = int(self.LabeltoECwgt)\n",
    "                print(\"ethreshold = \")\n",
    "                print(ethold)\n",
    "            elif patternIdx == 0:\n",
    "                wsrc = self.numMCs\n",
    "                thold = init_th(wsrc, patternIdx, self.inhid_vth, 255)\n",
    "                self.biasMn = int(thold / 10)\n",
    "                ref = 1\n",
    "                if self.numlayers == 2:\n",
    "                    ethold = int(self.LabeltoECwgt)\n",
    "                else:\n",
    "                    ethold = int(init_th(self.numHidNurns[patternIdx + 1], patternIdx, self.inhid_vth, 255) / (patternIdx + 2))\n",
    "\n",
    "            else:\n",
    "                wsrc = self.numHidNurns[patternIdx - 1]\n",
    "                thold = init_th(wsrc, patternIdx, self.hid_vth, 255)\n",
    "                self.biasMn = int(thold / 10)\n",
    "                ref = 1\n",
    "                ethold = int(init_th(self.numHidNurns[patternIdx + 1], patternIdx, self.hid_vth, 255) / (patternIdx + 2))\n",
    "            \n",
    "            \n",
    "            # du,dv,vth = converter(self.curdcy,self.voldcy,thold)\n",
    "            self.hiddens[patternIdx] =self.create_cx(patternIdx = patternIdx,\n",
    "                                                            du = self.curdcy,dv= self.voldcy,vth = thold, bias_mant= self.biasMn,\n",
    "                                                            bias_exp = self.biasEx,\n",
    "                                                            vmin_exp= 20\n",
    "                                                        \n",
    "                                                            )\n",
    "            \n",
    "    #create input neurons\n",
    "    def createMCNeurons(self, biasMant=0):\n",
    "        du =0\n",
    "        dv =0\n",
    "        vth =4*4\n",
    "        du,dv,vth = converter(du,dv,vth)\n",
    "        '''\n",
    "        input neurons\n",
    "        '''\n",
    "        print(\"mc du is \", du)\n",
    "        mcSomaCx = Lif(\n",
    "            shape = (self.numMCs,),\n",
    "            du =du,\n",
    "            dv = dv,\n",
    "            vth = vth,\n",
    "            vmin_exp = 0,\n",
    "            name = \"train\"\n",
    "        )\n",
    "        self.allMCSomaGrp = mcSomaCx\n",
    "    #create input neurons\n",
    "    def createTestInputs(self, biasMant=0):\n",
    "        du =0\n",
    "        dv =0\n",
    "        vth =4*4\n",
    "        du,dv,vth = converter(du,dv,vth)\n",
    "        '''\n",
    "        input neurons\n",
    "        '''\n",
    "        test_mc =Lif(\n",
    "            shape = (self.numMCs,),\n",
    "            du =du,\n",
    "            dv = dv,\n",
    "            vth = vth,\n",
    "            vmin_exp = 0,\n",
    "            name = \"test\"\n",
    "        )\n",
    "        self.inputs = test_mc\n",
    "        \n",
    "    def createGCNeuronsPerPattern(self, patternIdx):\n",
    "            \n",
    "        self.inhid_vth = 0.5 #0.3 # first layer threshold\n",
    "        self.hid_vth = 0.3 # middle layer threshold\n",
    "        self.classifier_vth = 0.3 # 0.5 # classifier layer threshold\n",
    "        self.biasEx = 2 # bias exponential\n",
    "        self.biasMn = 1 # bias mantissa default\n",
    "\n",
    "        scale = 1\n",
    "        self.GCtoECDelayDeriv = int(10)\n",
    "        # self.ECtoGCDelayDeriv = int(2)\n",
    "        self.wtadelay = int(0)\n",
    "        # self.lastECdelay = int(0)\n",
    "        self.voldcy = int(0)\n",
    "        self.curdcy = int(4000)\n",
    "\n",
    "        self.wtadelay = int(0)\n",
    "\n",
    "        self.ECtoGCwgt = 255\n",
    "        self.LabeltoECwgt = 8\n",
    "\n",
    "        thold = 0\n",
    "        wsrc = 0\n",
    "        \n",
    "        # calculating forward and error path thresholds\n",
    "        if patternIdx == self.numlayers - 1:\n",
    "            wsrc = self.numHidNurns[patternIdx - 1]\n",
    "            thold = init_th(wsrc, patternIdx, self.classifier_vth, 255)\n",
    "            self.biasMn = int(thold / 10)\n",
    "            ref = 1\n",
    "            ethold = int(self.LabeltoECwgt)\n",
    "            print(\"ethreshold = \")\n",
    "            print(ethold)\n",
    "        elif patternIdx == 0:\n",
    "            wsrc = self.numMCs\n",
    "            thold = init_th(wsrc, patternIdx, self.inhid_vth, 255)\n",
    "            self.biasMn = int(thold / 10)\n",
    "            ref = 1\n",
    "            if self.numlayers == 2:\n",
    "                ethold = int(self.LabeltoECwgt)\n",
    "            else:\n",
    "                ethold = int(init_th(self.numHidNurns[patternIdx + 1], patternIdx, self.inhid_vth, 255) / (patternIdx + 2))\n",
    "\n",
    "        else:\n",
    "            wsrc = self.numHidNurns[patternIdx - 1]\n",
    "            thold = init_th(wsrc, patternIdx, self.hid_vth, 255)\n",
    "            self.biasMn = int(thold / 10)\n",
    "            ref = 1\n",
    "            ethold = int(init_th(self.numHidNurns[patternIdx + 1], patternIdx, self.hid_vth, 255) / (patternIdx + 2))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.allGCsPerPattern[patternIdx] =self.create_cx(patternIdx = patternIdx,\n",
    "                                                          du = self.curdcy,dv=self.voldcy,vth = thold, bias_mant= self.biasMn,\n",
    "                                                          bias_exp = self.biasEx,\n",
    "                                                          vmax_exp=20)\n",
    "        \n",
    "\n",
    "        # creating connections from the error network to the forward path\n",
    "        # hidden layer connections\n",
    "        if patternIdx != self.numlayers - 1:\n",
    "            \n",
    "            posECtoTmpEC_conn = Dense(\n",
    "                weights = 10*np.eye(self.numHidNurns[patternIdx]),\n",
    "                num_weight_bits = 8,\n",
    "                sign_mode = SignMode.MIXED\n",
    "            )\n",
    "\n",
    "            '''\n",
    "            to do connection 1: pos ec soma -> tmp pos ec\n",
    "            weight = 10\n",
    "            '''\n",
    "            # pos_ec to tmp ec\n",
    "            # src: pos ec soma\n",
    "            # dst: tmp pos ec \n",
    "            self.allPosECsPerPattern[patternIdx].s_out.connect(posECtoTmpEC_conn.s_in)\n",
    "            posECtoTmpEC_conn.a_out.connect(self.allTmpPosECsPerPattern[patternIdx].a_in)\n",
    "            \n",
    "            '''\n",
    "            to do connection 2: neg ec soma-> tmp neg ec \n",
    "            weight = 10\n",
    "            '''\n",
    "            negECtoTmpEC_conn = Dense(\n",
    "                weights = 10*np.eye(self.numHidNurns[patternIdx]),\n",
    "                num_weight_bits = 8,\n",
    "                sign_mode = SignMode.MIXED\n",
    "            )\n",
    "            self.allNegECsPerPattern[patternIdx].s_out.connect(negECtoTmpEC_conn.s_in)\n",
    "            negECtoTmpEC_conn.a_out.connect(self.allTmpNegECsPerPattern[patternIdx].a_in)\n",
    "            \n",
    "            '''\n",
    "            to do connection 3: \n",
    "            src tmp pos EC-> dst gc(forward)\n",
    "            weights: self.ECtoGCwgt\n",
    "            weight_exp: ijexp\n",
    "            '''\n",
    "            tmpPosECtoGCconns = Dense(\n",
    "                weights = self.ECtoGCwgt*(np.eye(self.numHidNurns[patternIdx]).astype(int)),\n",
    "                num_weight_bits = 8,\n",
    "                weight_exp = self.wgt_exp[patternIdx],\n",
    "                sign_mode = SignMode.MIXED\n",
    "            )\n",
    "            self.allTmpPosECsPerPattern[patternIdx].s_out.connect(tmpPosECtoGCconns.s_in)\n",
    "            tmpPosECtoGCconns.a_out.connect(self.allGCsPerPattern[patternIdx].a_in)\n",
    "            \n",
    "            '''\n",
    "            to do connection 4:\n",
    "            src tmp neg ec-> gc\n",
    "            weight: -self.ECtoGCwgt\n",
    "            weight_exp: ijexp\n",
    "            '''\n",
    "            tmpnegECtoGCConns = Dense (\n",
    "                weights = -self.ECtoGCwgt*(np.eye(self.numHidNurns[patternIdx]).astype(int)),\n",
    "                num_weight_bits = 8,\n",
    "                weight_exp = self.wgt_exp[patternIdx],\n",
    "                sign_mode = SignMode.MIXED\n",
    "            \n",
    "            )\n",
    "            self.allTmpNegECsPerPattern[patternIdx].s_out.connect(tmpnegECtoGCConns.s_in)\n",
    "            tmpnegECtoGCConns.a_out.connect(self.allGCsPerPattern[patternIdx].a_in)\n",
    "            \n",
    "            \n",
    "            ##########################\n",
    "            # creating connections from the forward path to auxilary error compartments to perform the derivative\n",
    "            '''\n",
    "            to do connection 5:\n",
    "            using delay dense here:\n",
    "            postSynResponseMode=nx.SYNAPSE_POST_SYN_RESPONSE_MODE.BOX, current remain a constant.\n",
    "            weight = 10, np eye\n",
    "            src GC -> dst pos EC dendrite[0]\n",
    "            \n",
    "            '''\n",
    "            posGCtoECConns = DelayDense(\n",
    "                weights = 10*np.eye(self.numHidNurns[patternIdx]).astype(int),\n",
    "                num_weight_bits = 8,\n",
    "                sign_mode = SignMode.MIXED,\n",
    "                delays = self.GCtoECDelayDeriv\n",
    "            )\n",
    "            \n",
    "            self.allGCsPerPattern[patternIdx].s_out.connect(posGCtoECConns.s_in)\n",
    "            posGCtoECConns.a_out.connect(self.pos_ec_dendrite.a_in)\n",
    "            \n",
    "            '''\n",
    "            to do connection 6:\n",
    "            DenseDelay\n",
    "            weight =10,\n",
    "            src GC -> dst neg EC dendrite[0]\n",
    "            '''\n",
    "            negGCtoECConns = DelayDense(\n",
    "                weights = 10*np.eye(self.numHidNurns[patternIdx]).astype(int),\n",
    "                num_weight_bits = 8,\n",
    "                sign_mode = SignMode.MIXED,\n",
    "                delays = self.GCtoECDelayDeriv\n",
    "            )\n",
    "            self.allGCsPerPattern[patternIdx].s_out.connect(negGCtoECConns.s_in)\n",
    "            negGCtoECConns.a_out.connect(self.neg_ec_dendrite.a_in)\n",
    "\n",
    "        # for classifier layer\n",
    "        if patternIdx == self.numlayers - 1:\n",
    "            \n",
    "          ########################################################\n",
    "            # loss computation through spikes at the top layer of error path using connections from classifier and label\n",
    "            labelscale = 1.5\n",
    "            gcscale = 2\n",
    "\n",
    "            \n",
    "            '''\n",
    "            to do connection 7\n",
    "            weight: -int(self.LabeltoECwgt * gcscale), np eye\n",
    "            src GC-> dst pos EC\n",
    "            '''\n",
    "            GCtoPosECConn = Dense(\n",
    "                weights = -int(self.LabeltoECwgt * gcscale)*np.eye(self.numHidNurns[patternIdx]),\n",
    "                num_weight_bits = 8,\n",
    "                sign_mode = SignMode.MIXED\n",
    "            )\n",
    "            self.allGCsPerPattern[patternIdx].s_out.connect(GCtoPosECConn.s_in)\n",
    "            GCtoPosECConn.a_out.connect(self.allPosECsPerPattern[patternIdx].a_in)\n",
    "            \n",
    "            '''\n",
    "            to do connection 8\n",
    "            weights: int(self.LabeltoECwgt * labelscale), np eye\n",
    "            src label -> dst pos ec\n",
    "            '''\n",
    "            LabeltoPosECConn = Dense(\n",
    "                weights = int(self.LabeltoECwgt * labelscale)*np.eye(self.numHidNurns[patternIdx]),\n",
    "                num_weight_bits = 8,\n",
    "                sign_mode = SignMode.MIXED\n",
    "            )\n",
    "            self.allLabelGrp.s_out.connect(LabeltoPosECConn.s_in)\n",
    "            LabeltoPosECConn.a_out.connect(self.allPosECsPerPattern[patternIdx].a_in)\n",
    "            '''\n",
    "            to do connection 9:\n",
    "            src GC -> dst neg EC\n",
    "            weights: int(self.LabeltoECwgt * labelscale) np eye\n",
    "            '''\n",
    "            GCtoNegECConn = Dense(\n",
    "                weights = int(self.LabeltoECwgt * labelscale)*np.eye(self.numHidNurns[patternIdx]),\n",
    "                num_weight_bits = 8,\n",
    "                sign_mode = SignMode.MIXED\n",
    "             )\n",
    "            self.allGCsPerPattern[patternIdx].s_out.connect(GCtoNegECConn.s_in)\n",
    "            GCtoNegECConn.a_out.connect(self.allNegECsPerPattern[patternIdx].a_in)\n",
    "\n",
    "            '''\n",
    "            to do connection 10:\n",
    "            weights: -int(self.LabeltoECwgt * gcscale) np.eye(self.numHidNurns[patternIdx])\n",
    "            src  label -> dst neg EC\n",
    "            \n",
    "            '''\n",
    "            LabeltoNegECConn  = Dense(\n",
    "                weights = -int(self.LabeltoECwgt * gcscale)*np.eye(self.numHidNurns[patternIdx]),\n",
    "                num_weight_bits = 8,\n",
    "                sign_mode = SignMode.MIXED\n",
    "            )\n",
    "            self.allLabelGrp.s_out.connect(LabeltoNegECConn.s_in)\n",
    "            LabeltoNegECConn.a_out.connect(self.allNegECsPerPattern[patternIdx].a_in)\n",
    "            '''\n",
    "            to do connection 11:\n",
    "            weights: 10\n",
    "            connMAT\n",
    "            src pos EC -> dst tmp pos EC\n",
    "            '''\n",
    "            posECtoTmpPosEC = Dense(\n",
    "                weights = int(10)*np.eye(self.numHidNurns[patternIdx]),\n",
    "                num_weight_bits = 8,\n",
    "                sign_mode = SignMode.MIXED\n",
    "            )\n",
    "            self.allPosECsPerPattern[patternIdx].s_out.connect(posECtoTmpPosEC.s_in)\n",
    "            posECtoTmpPosEC.a_out.connect(self.allTmpPosECsPerPattern[patternIdx].a_in)\n",
    "            \n",
    "            '''\n",
    "            to do connection 12:\n",
    "            weights: 10\n",
    "            cnnMAT,\n",
    "            src  neg EC -> dst tmp neg EC\n",
    "            '''\n",
    "            negECtoTmpNegEC = Dense(\n",
    "                weights = int(10)*np.eye(self.numHidNurns[patternIdx]),\n",
    "                num_weight_bits = 8,\n",
    "                sign_mode = SignMode.MIXED\n",
    "            )\n",
    "            self.allNegECsPerPattern[patternIdx].s_out.connect(negECtoTmpNegEC.s_in)\n",
    "            negECtoTmpNegEC.a_out.connect(self.allTmpNegECsPerPattern[patternIdx].a_in)\n",
    "            \n",
    "            '''\n",
    "            to do connection 13\n",
    "            weights: int(self.ECtoGCwgt / 1) connMAT\n",
    "            weight_exp: ijexp\n",
    "            src tmp pos EC -> dst GC\n",
    "            '''\n",
    "            tmpPosECtoGC = Dense(\n",
    "                weights =int(self.ECtoGCwgt / 1)*np.eye(self.numHidNurns[patternIdx]),\n",
    "                num_weight_bits = 8,\n",
    "                weight_exp = self.wgt_exp[patternIdx],\n",
    "                sign_mode = SignMode.MIXED\n",
    "            )\n",
    "            self.allTmpPosECsPerPattern[patternIdx].s_out.connect(tmpPosECtoGC.s_in)\n",
    "            tmpPosECtoGC.a_out.connect(self.allGCsPerPattern[patternIdx].a_in)\n",
    "            '''\n",
    "            to do connection 14:\n",
    "            weights: -int(self.ECtoGCwgt / 1)\n",
    "            weight_exp: ijexp\n",
    "            src tmp neg EC -> dst GC\n",
    "            '''\n",
    "            tmpnegEctoGC = Dense(\n",
    "                weights =-int(self.ECtoGCwgt / 1)*np.eye(self.numHidNurns[patternIdx]),\n",
    "                num_weight_bits = 8,\n",
    "                weight_exp = self.wgt_exp[patternIdx],\n",
    "                sign_mode = SignMode.MIXED\n",
    "            )\n",
    "            self.allTmpNegECsPerPattern[patternIdx].s_out.connect(tmpnegEctoGC.s_in)\n",
    "            tmpnegEctoGC.a_out.connect(self.allGCsPerPattern[patternIdx].a_in)\n",
    "    \n",
    "    #reset some traces probes\n",
    "    def reset_traces(self):\n",
    "        '''\n",
    "        # # Learning Vars\n",
    "        # self.x0 = Var(shape=(shape[-1],), init=0)\n",
    "        # self.tx = Var(shape=(shape[-1],), init=0)\n",
    "        # self.y0 = Var(shape=(shape[0],), init=0)\n",
    "        # self.ty = Var\n",
    "        # '''\n",
    "        for i in range(self.numlayers):\n",
    "            self.forwardConns[i].x0 .set(np.zeros((self.forwardConns[i].weights.shape[-1],)).astype(int))\n",
    "            self.forwardConns[i].tx.set(np.zeros((self.forwardConns[i].weights.shape[-1],)).astype(int))\n",
    "            self.forwardConns[i].y0.set(np.zeros((self.forwardConns[i].weights.shape[0],)).astype(int))\n",
    "            self.forwardConns[i].ty.set(np.zeros((self.forwardConns[i].weights.shape[0],)).astype(int))\n",
    "\n",
    "    #reset some gc u and v\n",
    "    def reset_gc(self):\n",
    "        for i in range(self.numlayers):\n",
    "            self.allGCsPerPattern[i].u.set(np.zeros((self.numHidNurns[i]),).astype(int))\n",
    "            self.allGCsPerPattern[i].v.set(np.zeros((self.numHidNurns[i]),).astype(int))\n",
    "            \n",
    "    #Reset EC layers\n",
    "    def reset_ec(self,reset_mode = 0):\n",
    "        #if reset mode ==1, means training. set v and u to normal value\n",
    "        for i in range(self.numlayers):\n",
    "            if reset_mode:\n",
    "                self.allNegECsPerPattern[1].dv.set(np.zeros((1,)))\n",
    "                self.allPosECsPerPattern[1].dv.set(np.zeros((1,)))\n",
    "\n",
    "                self.allNegECsPerPattern[1].vth.set(int(8*2**6)*np.ones((1,)))\n",
    "                self.allPosECsPerPattern[1].vth.set(int(8*2**6)*np.ones((1,)))\n",
    "            else:\n",
    "                self.allNegECsPerPattern[0].dv.set(4095*np.ones((1,)))\n",
    "                self.allPosECsPerPattern[0].dv.set(4095*np.ones((1,)))\n",
    "\n",
    "                self.allNegECsPerPattern[0].vth.set(int(3255*2**6)*np.ones((1,)))\n",
    "                self.allPosECsPerPattern[0].vth.set(int(3255*2**6)*np.ones((1,)))\n",
    "\n",
    "\n",
    "    def connectforwardConns(self, train, wgt):\n",
    "        \"\"\" creates the GC->MC inhibitory connections for each pattern\"\"\"\n",
    "        lr = 4  # 2^-lr learning rate\n",
    "        lrt = lr + 1  # top layer learning rate\n",
    "        lp = 7  # u7 -> 2^7 learning period\n",
    "\n",
    "        top_x1TimeConstant = 64\n",
    "        top_y1TimeConstant = 64\n",
    "\n",
    "        hid_x1TimeConstant = 64\n",
    "        hid_y1TimeConstant = 64\n",
    "\n",
    "        dw_top = '2^-' + str(lrt) + '*u' + str(lp) + '*y1*x1 - 2^-' + str(lrt + 1) + '*u' + str(lp) + '*t*x1'\n",
    "        dw_hid = '2^-' + str(lr) + '*u' + str(lp) + '*y1*x1 - 2^-' + str(lr + 1) + '*u' + str(lp) + '*t*x1'\n",
    "\n",
    "        for pIdx in range(self.numlayers):\n",
    "            if pIdx == self.numlayers - 1:\n",
    "                lr = Loihi2FLearningRule(\n",
    "                    dd='2^0*x0 - 2^3*u7*d',\n",
    "                    dt='2^0*y0 - 2^0*u7*t',\n",
    "                    dw='2^-6*u7*y1*x1 - 2^-7*u7*t*x1',\n",
    "                    x1_impulse = 1,\n",
    "                    x1_tau = 32,\n",
    "                    y1_impulse = 1,\n",
    "                    y1_tau =128,\n",
    "                    y2_impulse = 1,\n",
    "                    y2_tau=4095,\n",
    "                    t_epoch =1 \n",
    "                )\n",
    "                #dw='2^-5*u7*y1*x1 - 2^-6*u7*t*x1' for MSTAR works better\n",
    "            else:\n",
    "                # single update per sample\n",
    "                lr = Loihi2FLearningRule(\n",
    "                    dd='2^0*x0 - 2^3*u7*d',\n",
    "                    dt='2^0*y0 - 2^0*u7*t',\n",
    "                    dw='2^-5*u7*y1*x1 - 2^-6*u7*t*x1',\n",
    "                    x1_impulse = 1,\n",
    "                    x1_tau = 32,\n",
    "                    y1_impulse = 1,\n",
    "                    y1_tau =128,\n",
    "                    y2_impulse = 1,\n",
    "                    y2_tau=4000,\n",
    "                    t_epoch=1)\n",
    "            \n",
    "            # if pIdx == self.numlayers - 1:\n",
    "                # single update per sample\n",
    "            #     lr = Loihi2FLearningRule(\n",
    "            #         # dd='2^0*x0 - 2^3*u7*d',\n",
    "            #         dt='2^0*y0 - 2^0*u7*t',\n",
    "            #         dw=dw_top,  # add decay term\n",
    "            #         x1_impulse=1,\n",
    "            #         x1_tau=top_x1TimeConstant,\n",
    "            #         y1_impulse=1,\n",
    "            #         y1_tau=top_y1TimeConstant,\n",
    "            #         x2_impulse=1,\n",
    "            #         x2_tau=64,\n",
    "            #         t_epoch=1)\n",
    "            # elif pIdx == 0:\n",
    "            #     # single update per sample\n",
    "            #     lr = Loihi2FLearningRule(\n",
    "            #         # dd='2^0*x0 - 2^3*u7*d',\n",
    "            #         dt='2^0*y0 - 2^0*u7*t',\n",
    "            #         dw=dw_hid,\n",
    "            #         x1_impulse=1,\n",
    "            #         x1_tau=hid_x1TimeConstant,\n",
    "            #         y1_impulse=1,\n",
    "            #         y1_tau=hid_y1TimeConstant,\n",
    "            #         x2_impulse=1,\n",
    "            #         x2_tau=64,\n",
    "            #         t_epoch=1)\n",
    "            # else:\n",
    "            #     # single update per sample\n",
    "            #     lr = Loihi2FLearningRule(\n",
    "            #         # dd='2^0*x0 - 2^3*u7*d',\n",
    "            #         dt='2^0*y0 - 2^0*u7*t',\n",
    "            #         dw=dw_hid,\n",
    "            #         x1_impulse=1,\n",
    "            #         x1_tau=hid_x1TimeConstant,\n",
    "            #         y1_impulse=1,\n",
    "            #         y1_tau=hid_y1TimeConstant,\n",
    "            #         x2_impulse=1,\n",
    "            #         x2_tau=64,\n",
    "            #         t_epoch=1)\n",
    "\n",
    "            if pIdx == 0:\n",
    "                # forWgts = np.ones((self.numHidNurns[pIdx], self.numMCs), int)*4\n",
    "                if len(wgt) == 0:\n",
    "                    forWgts = init_wgts(self.negwgtrng, self.poswgtrng, self.numHidNurns[pIdx], self.numMCs, pIdx)\n",
    "                    # forWgts = np.random.randint(low=self.negwgtrng, high=self.poswgtrng, size=(self.numHidNurns[pIdx], self.numMCs), dtype=int)\n",
    "                else:\n",
    "                    forWgts = self.hid_wgt\n",
    "\n",
    "                forConnGrp_1 = LearningDense(\n",
    "                    weights = forWgts,\n",
    "                    learning_rule= lr,\n",
    "                    num_weight_bits = 8,\n",
    "                    sign_mode = SignMode.MIXED,\n",
    "                    name = 'input_hidden_conn'\n",
    "                    \n",
    "                )\n",
    "\n",
    "                self.forwardConns[pIdx] = forConnGrp_1\n",
    "                self.allMCSomaGrp.s_out.connect(forConnGrp_1.s_in)\n",
    "                forConnGrp_1.a_out.connect(self.allGCsPerPattern[pIdx].a_in)\n",
    "                #backward connecions\n",
    "                self.allGCsPerPattern[pIdx].s_out.connect(forConnGrp_1.s_in_bap)\n",
    "\n",
    "            else:\n",
    "                if len(wgt) == 0:\n",
    "                    forWgts = init_wgts(self.negwgtrng, self.poswgtrng, self.numHidNurns[pIdx],\n",
    "                                        self.numHidNurns[pIdx - 1], pIdx)\n",
    "                else:\n",
    "                    forWgts = self.out_wgt\n",
    "\n",
    "                #                 print(forWgts)\n",
    "\n",
    "                forConnGrp_2 = LearningDense(\n",
    "                    weights = forWgts,\n",
    "                    learning_rule= lr,\n",
    "                    num_weight_bits = 8,\n",
    "                    sign_mode = SignMode.MIXED,\n",
    "                    name = 'hid_out_conn'\n",
    "                    \n",
    "                )\n",
    "\n",
    "                self.forwardConns[pIdx] = forConnGrp_2\n",
    "                self.allGCsPerPattern[pIdx-1].s_out.connect(forConnGrp_2.s_in)\n",
    "                forConnGrp_2.a_out.connect(self.allGCsPerPattern[pIdx].a_in)\n",
    "                #backward connections for the second layer\n",
    "                self.allGCsPerPattern[pIdx].s_out.connect(forConnGrp_2.s_in_bap)\n",
    "                \n",
    "    def connectbackwardConns(self, bwgt):\n",
    "        # connections for the error path\n",
    "        for pIdx in range(self.numlayers):\n",
    "\n",
    "            if pIdx == 0:\n",
    "                # self.backwardConns[pIdx] = self.net.createConnectionGroup()\n",
    "                self.posbackwardConns[pIdx] = []\n",
    "                self.negbackwardConns[pIdx] = []\n",
    "                self.posbackwardConns[pIdx + 1] = []\n",
    "                self.negbackwardConns[pIdx + 1] = []\n",
    "\n",
    "            elif pIdx == self.numlayers - 1:\n",
    "\n",
    "                if len(bwgt) == 0:\n",
    "                    # posbackWgts = init_wgts(self.negwgtrng, self.poswgtrng, self.numHidNurns[pIdx-1], self.numHidNurns[pIdx])\n",
    "                    posbackWgts = np.random.randint(low=self.bnegwgtrng, high=self.bposwgtrng,\n",
    "                                                    size=(self.numHidNurns[pIdx - 1], self.numHidNurns[pIdx]),\n",
    "                                                    dtype=int)\n",
    "                else:\n",
    "                    posbackWgts = bwgt[pIdx].T\n",
    "\n",
    "                negbackWgts = - posbackWgts\n",
    "\n",
    "                #error layer\n",
    "                # src: pos ec ->pos ec soma\n",
    "                # weights - posbackWgts\n",
    "                posECtoSomaConn = Dense(\n",
    "                    weights = posbackWgts,\n",
    "                    num_weight_bits = 8,\n",
    "                    sign_mode = SignMode.MIXED\n",
    "                )\n",
    "                self.allPosECsPerPattern[pIdx].s_out.connect(posECtoSomaConn.s_in)\n",
    "                posECtoSomaConn.a_out.connect(self.pos_ec_soma.a_in)\n",
    "\n",
    "                #src: neg EC pidx -> dst: pos EC soma pidx -1\n",
    "                # negbackwgts\n",
    "\n",
    "                negECtpPosECsoma = Dense(\n",
    "                   weights = negbackWgts,\n",
    "                     num_weight_bits = 8,\n",
    "                    sign_mode = SignMode.MIXED\n",
    "               )\n",
    "                self.allNegECsPerPattern[pIdx].s_out.connect(negECtpPosECsoma.s_in)\n",
    "                negECtpPosECsoma.a_out.connect(self.pos_ec_soma.a_in)\n",
    "\n",
    "                # src: neg ec Pidx -> dst neg ec pidx -1 soma\n",
    "                # weights = posbackWgts\n",
    "                negECtonegECsoma = Dense(\n",
    "                    weights = posbackWgts,\n",
    "                    num_weight_bits = 8,\n",
    "                    sign_mode = SignMode.MIXED\n",
    "                )\n",
    "                self.allNegECsPerPattern[pIdx].s_out.connect(negECtonegECsoma.s_in)\n",
    "                negECtonegECsoma.a_out.connect(self.neg_ec_soma.a_in)\n",
    "\n",
    "                #src: posec pidx ->dst : negec soma \n",
    "                # weights negbacl wgts\n",
    "                posECtonegsoma = Dense(weights = negbackWgts,\n",
    "                num_weight_bits = 8,\n",
    "                sign_mode = SignMode.MIXED\n",
    "                                       )\n",
    "                self.allPosECsPerPattern[pIdx].s_out.connect(posECtonegsoma.s_in)\n",
    "                posECtonegsoma.a_out.connect(self.neg_ec_soma.a_in)\n",
    "\n",
    "                '''\n",
    "                connect soma, dendrite to the final neuron\n",
    "                weight =10\n",
    "                '''\n",
    "                pos_soma_conn = Dense(\n",
    "                    weights = int(2)*np.eye(self.numHidNurns[pIdx-1]),\n",
    "                    num_weight_bits = 8,\n",
    "                    sign_mode = SignMode.MIXED\n",
    "                )\n",
    "                pos_dendrite_conn = Dense(\n",
    "                    weights = int(2)**np.eye(self.numHidNurns[pIdx-1]),\n",
    "                    num_weight_bits = 8,\n",
    "                    sign_mode = SignMode.MIXED\n",
    "                )\n",
    "\n",
    "                self.pos_ec_soma.s_out.connect(pos_soma_conn.s_in)\n",
    "                pos_soma_conn.a_out.connect(self.allPosECsPerPattern[pIdx-1].a_in)\n",
    "\n",
    "                self.pos_ec_dendrite.s_out.connect(pos_dendrite_conn.s_in)\n",
    "                pos_dendrite_conn.a_out.connect(self.allPosECsPerPattern[pIdx-1].a_in)\n",
    "\n",
    "                neg_soma_conn = Dense(\n",
    "                    weights = int(2)*np.eye(self.numHidNurns[pIdx-1]),\n",
    "                    num_weight_bits = 8\n",
    "                )\n",
    "                neg_dendrite_conn = Dense(\n",
    "                    weights = int(2)**np.eye(self.numHidNurns[pIdx-1]),\n",
    "                    num_weight_bits = 8\n",
    "                )\n",
    "\n",
    "                self.neg_ec_soma.s_out.connect(neg_soma_conn.s_in)\n",
    "                neg_soma_conn.a_out.connect(self.allNegECsPerPattern[pIdx-1].a_in)\n",
    "\n",
    "                self.neg_ec_dendrite.s_out.connect(neg_dendrite_conn.s_in)\n",
    "                neg_dendrite_conn.a_out.connect(self.allNegECsPerPattern[pIdx-1].a_in)\n",
    "\n",
    "\n",
    "            else:\n",
    "                '''\n",
    "                more than two learning layers\n",
    "                '''\n",
    "                print(\"to do: more than 3 hidden layers\")\n",
    "\n",
    "    def idxToBases(self, inputList):\n",
    "        \"\"\" maps the input data/sensor reading to an MC-AD bias current\"\"\"\n",
    "        # inputList = list(inputList)\n",
    "        # return [self.stim2bias[i] for i in inputList]\n",
    "        return inputList\n",
    "\n",
    "    def generate_data(self,train_data):\n",
    "        '''\n",
    "        train_data shape: N,200\n",
    "        '''\n",
    "        for i in range(len(train_data)):\n",
    "            #arange train data\n",
    "            self.train_data.append(self.idxToBases(train_data[0][i]))\n",
    "\n",
    "    '''\n",
    "    define probes for the network\n",
    "    ''' \n",
    "    def probes(self,num_img=1):\n",
    "        out_spikes = Monitor()\n",
    "        out_spikes.probe(self.allGCsPerPattern[-1].s_out,self.num_steps*num_img)\n",
    "\n",
    "        return out_spikes\n",
    "    \n",
    "    #set up training parameters \n",
    "    def set_label_para(self,label):\n",
    "        #set up label data to the label layer\n",
    "        self.allLabelGrp.bias_mant.set(label)\n",
    "\n",
    "\n",
    "    '''\n",
    "    set up another network to do the inference\n",
    "    '''\n",
    "\n",
    "    def test(self,imgs,hid_wgt = [] , out_wgt = [] ,num_steps = 128):\n",
    "        #create connections\n",
    "        #reconstruct input:\n",
    "        self.createTestInputs()\n",
    "        for patternIdx in range(self.numlayers):\n",
    "            self.createTestGC(patternIdx= patternIdx)\n",
    "        if len(hid_wgt) ==0:\n",
    "            hid_weights = self.hid_wgt\n",
    "            out_weights = self.out_wgt\n",
    "        else:\n",
    "            hid_weights = hid_wgt\n",
    "            out_weights = out_wgt\n",
    "            \n",
    "        self.test_inter = Dense(\n",
    "            weights = hid_weights\n",
    "        )\n",
    "        self.test_out = Dense(\n",
    "            weights = out_weights\n",
    "        )\n",
    "        # first layer connection\n",
    "        self.inputs.s_out.connect(self.test_inter.s_in)\n",
    "        self.test_inter.a_out.connect(self.hiddens[0].a_in)\n",
    "        # second layer connection\n",
    "        self.hiddens[0].s_out.connect(self.test_out.s_in)\n",
    "        self.test_out.a_out.connect(self.hiddens[1].a_in)\n",
    "\n",
    "        #probes for the spikes\n",
    "        out_probe = Monitor()\n",
    "        out_probe.probe(self.hiddens[1].s_out, 1+len(imgs)*num_steps)\n",
    "        self.inputs.run(condition=RunSteps(num_steps= 1), run_cfg=Loihi2HwCfg(\n",
    "            select_tag = SELECT_TAG\n",
    "        ))\n",
    "        # running test cases\n",
    "        for i in range(len(imgs)):\n",
    "            #converting img input to integer\n",
    "            img = imgs[i]\n",
    "            self.inputs.bias_mant.set(img)\n",
    "            #running the network\n",
    "            self.inputs.run(condition=RunSteps(num_steps= num_steps), run_cfg=Loihi2HwCfg(\n",
    "            select_tag = SELECT_TAG\n",
    "        ))\n",
    "            \n",
    "        spikes = out_probe.get_data()[self.hiddens[1].name]['s_out']\n",
    "        self.inputs.stop()\n",
    "        result = np.zeros((len(imgs),10))\n",
    "        for j in range(len(imgs)):\n",
    "            tmp = np.sum(spikes[j*(num_steps):(j+1)*num_steps,:],axis =0)\n",
    "            result[j,:] = tmp\n",
    "        print(result)\n",
    "        res = np.argmax(result,axis =-1)\n",
    "\n",
    "        return res\n",
    "        \n",
    "    '''\n",
    "    t =0 : send initialized data\n",
    "    t = 1: reset, apply labels\n",
    "    t = 2: apply input\n",
    "    '''\n",
    "    def fit(self,imgs,labels,num_steps=128):\n",
    "        '''\n",
    "        run for just one time step, for the bias setting purpose\n",
    "        '''\n",
    "        # hid_wgt,out_wgt = self.weight_probe(img)\n",
    "        probe = Monitor()\n",
    "        probe.probe(self.allGCsPerPattern[1].s_out,1+len(imgs)*128)\n",
    "        self.allMCSomaGrp.run(condition=RunSteps(num_steps= 1), run_cfg=Loihi2HwCfg(\n",
    "            select_tag = 'fixed_pt'\n",
    "        ))\n",
    "        '''\n",
    "        set up probes\n",
    "        '''\n",
    "        for i in range(len(imgs)):\n",
    "            train = False\n",
    "            '''\n",
    "            reset all forward layers intermediate values\n",
    "            '''\n",
    "\n",
    "            '''\n",
    "            set up input data to bias\n",
    "            set up label layer parameters\n",
    "            '''\n",
    "            img = imgs[i]\n",
    "            '''\n",
    "            Reset GC, Reset EC neurons\n",
    "            '''\n",
    "            self.allMCSomaGrp.bias_mant.set(img)\n",
    "            self.set_label_para(labels[i])\n",
    "            #self.reset_ec()\n",
    "            self.reset_gc()\n",
    "           \n",
    "            #set labels\n",
    "            \n",
    "            # run first 64 timesteps:\n",
    "            self.allMCSomaGrp.run(condition=RunSteps(num_steps= num_steps//2), run_cfg=Loihi2HwCfg(\n",
    "                    select_tag = SELECT_TAG))\n",
    "            '''\n",
    "            Reset GCs, ECS\n",
    "            '''\n",
    "            self.set_label_para(labels[i])\n",
    "            self.reset_gc()\n",
    "            self.reset_ec(reset_mode=1)\n",
    "            '''\n",
    "            Reset learning traces\n",
    "            '''\n",
    "            self.reset_traces()\n",
    "            \n",
    "\n",
    "            self.allMCSomaGrp.run(condition=RunSteps(num_steps= num_steps//2), run_cfg=Loihi2HwCfg(select_tag= SELECT_TAG))\n",
    "            '''\n",
    "            Uncomment it if you need the dynamics of the weight.\n",
    "            '''\n",
    "            # hid_wgt.get_data()['input_hid_conn']['weights'][-1]\n",
    "            # out_wgt.get_data()['hid_out_conn']['weights'][-1]\n",
    "        self.hid_wgt = self.forwardConns[0].weights.get()\n",
    "        self.out_wgt = self.forwardConns[1].weights.get()\n",
    "        spikes = probe.get_data()[self.allGCsPerPattern[1].name]['s_out']\n",
    "        self.allMCSomaGrp.stop()\n",
    "        #print non zero elements\n",
    "        #print(np.count_nonzero(spikes))\n",
    "        spikes = spikes[1:]\n",
    "        result = np.zeros((len(imgs),10))\n",
    "        for j in range(len(imgs)):\n",
    "            tmp = np.sum(spikes[j*(num_steps):(j+1)*num_steps,:],axis =0)\n",
    "            result[j,:] = tmp\n",
    "        print(result[-10:])\n",
    "        res = np.argmax(result,axis =-1)\n",
    "        #print the last 10 spiking results\n",
    "        print(res[-10])\n",
    "        # #saving weigt\n",
    "        np.save(\"hid_wgt\",self.hid_wgt)\n",
    "        np.save(\"out_wgt\",self.out_wgt)\n",
    "\n",
    "        #return weights\n",
    "    def weights(self):\n",
    "        return self.hid_wgt, self.out_wgt \n",
    "\n",
    "#Here is the example usage of the testing cases\n",
    "network = emstdp()\n",
    "#setup network\n",
    "network.setupNetwork(True,[],[])\n",
    "\n",
    "#testing data\n",
    "imgs = np.load(\"x_train.npy\")\n",
    "labels = np.load(\"y_train.npy\")\n",
    "imgs = imgs/np.max(imgs)\n",
    "#construct the single imgs set\n",
    "train_data = np.zeros((50,200))\n",
    "train_label = np.zeros((50,10))\n",
    "imgs = (2*256*imgs).astype(int)\n",
    "# train_data = imgs[:100]\n",
    "# train_lable = labels[:100]\n",
    "for i in range(50):\n",
    "    train_data[i] = imgs[5]\n",
    "    train_label[i] = labels[5]\n",
    "    idx = np.argmax(labels[5])\n",
    "    train_label[i,idx] = 128\n",
    "\n",
    "test_data = train_data[:2]\n",
    "print(train_label.shape)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0ca46ac-5e32-404b-922b-0a1e42190722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time 1708528990.2546508\n",
      "Encountered Fatal Exception: Unsupported type\n",
      "Traceback: \n",
      "Traceback (most recent call last):\n",
      "  File \"/homes/zmei05/lava-0.6/lib/python3.8/site-packages/lava/magma/runtime/runtime.py\", line 98, in target_fn\n",
      "    actor.start(*args, **kwargs)\n",
      "  File \"/homes/zmei05/lava-0.6/lib/python3.8/site-packages/lava/magma/core/model/py/model.py\", line 93, in start\n",
      "    self.run()\n",
      "  File \"/homes/zmei05/lava-0.6/lib/python3.8/site-packages/lava/magma/core/model/py/model.py\", line 232, in run\n",
      "    raise inst\n",
      "  File \"/homes/zmei05/lava-0.6/lib/python3.8/site-packages/lava/magma/core/model/py/model.py\", line 218, in run\n",
      "    self._cmd_handlers[cmd]()\n",
      "  File \"/homes/zmei05/lava-0.6/lib/python3.8/site-packages/lava/magma/core/model/py/model.py\", line 198, in _set_var\n",
      "    raise RuntimeError(\"Unsupported type\")\n",
      "RuntimeError: Unsupported type\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Var Set couldn't get successfully completed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart time\u001b[39m\u001b[38;5;124m\"\u001b[39m,start)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#test network \u001b[39;00m\n\u001b[1;32m      5\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[13], line 1166\u001b[0m, in \u001b[0;36memstdp.fit\u001b[0;34m(self, imgs, labels, num_steps)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_label_para(labels[i])\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_gc()\n\u001b[0;32m-> 1166\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_ec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreset_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;124;03mReset learning traces\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_traces()\n",
      "Cell \u001b[0;32mIn[13], line 782\u001b[0m, in \u001b[0;36memstdp.reset_ec\u001b[0;34m(self, reset_mode)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumlayers):\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reset_mode:\n\u001b[0;32m--> 782\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallNegECsPerPattern\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallPosECsPerPattern[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdv\u001b[38;5;241m.\u001b[39mset(np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m,)))\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallNegECsPerPattern[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvth\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m8\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m1\u001b[39m,)))\n",
      "File \u001b[0;32m~/lava-0.6/lib/python3.8/site-packages/lava/magma/core/process/variable.py:159\u001b[0m, in \u001b[0;36mVar.set\u001b[0;34m(self, value, idx)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndices and number of non-zero \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements must stay equal when using\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset on a sparse matrix.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m         value \u001b[38;5;241m=\u001b[39m val\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruntime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_var\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo Runtime available yet. Cannot set new \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVar\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m without \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRuntime.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n",
      "File \u001b[0;32m~/lava-0.6/lib/python3.8/site-packages/lava/magma/runtime/runtime.py:508\u001b[0m, in \u001b[0;36mRuntime.set_var\u001b[0;34m(self, var_id, value, idx)\u001b[0m\n\u001b[1;32m    506\u001b[0m     rsp \u001b[38;5;241m=\u001b[39m rsp_port\u001b[38;5;241m.\u001b[39mrecv()\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m enum_equal(rsp, MGMT_RESPONSE\u001b[38;5;241m.\u001b[39mSET_COMPLETE):\n\u001b[0;32m--> 508\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVar Set couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt get successfully \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m                            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRuntime has not started\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Var Set couldn't get successfully completed"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"start time\",start)\n",
    "network.fit(imgs = train_data,labels=train_label)\n",
    "#test network \n",
    "end = time.time()\n",
    "print(\"elapsed time: \", end -start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382648e7-1bae-41ca-90fd-4c2339f3ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1,2,3,4,5,7])\n",
    "min = -2**3\n",
    "print(min)\n",
    "a[a<min] =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4571f148-b0ec-4be1-a4f6-52a78541bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f4ba79-809b-4ae3-a2a2-3fb7f799ab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.array([1,2,3,4,5,6])\n",
    "u[:] = u*((2**12-0)//2**12)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e26cd4e9-5c98-40ea-9a7c-cc90f074df33",
   "metadata": {},
   "source": [
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648d055-4329-4a06-aae6-2e5a9b92bc62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
